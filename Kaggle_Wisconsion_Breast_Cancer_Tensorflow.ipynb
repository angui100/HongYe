{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_Wisconsion_Breast_Cancer_Tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMxGrvgG5DF6RlGPKsiOfw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/angui100/HongYe/blob/master/Kaggle_Wisconsion_Breast_Cancer_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9ecqynGaAal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "c98550ac-533f-46be-c014-accd3c59da3b"
      },
      "source": [
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEnIlKaAaN09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ed8b8ae6-b6ee-44bb-fc47-3b82dea03413"
      },
      "source": [
        "#prepare for data file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42UwhSwCbuaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_filename = '/content/drive/My Drive/dataset/wdbc.data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJerwvrDb7hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idKey = \"id\"\n",
        "diagnosisKey = \"diagnosis\"\n",
        "radiusMeanKey = \"radius_mean\"\n",
        "textureMeanKey = \"texture_mean\"\n",
        "perimeterMeanKey = \"perimeter_mean\"\n",
        "areaMeanKey = \"area_mean\"\n",
        "smoothnessMeanKey = \"smoothness_mean\"\n",
        "compactnessMeanKey = \"compactness_mean\"\n",
        "concavityMeanKey = \"concavity_mean\"\n",
        "concavePointsMeanKey = \"concave points_mean\"\n",
        "symmetryMeanKey = \"symmetry_mean\"\n",
        "fractalDimensionMean = \"fractal_dimension_mean\"\n",
        "radiusSeKey = \"radius_se\"\n",
        "textureSeKey = \"texture_se\"\n",
        "perimeterSeKey = \"perimeter_se\"\n",
        "areaSeKey = \"area_se\"\n",
        "smoothnessSeKey = \"smoothness_se\"\n",
        "compactnessSeKey = \"compactness_se\"\n",
        "concavitySeKey = \"concavity_se\"\n",
        "concavePointsSeKey = \"concave points_se\"\n",
        "symmetrySeKey = \"symmetry_se\"\n",
        "fractalDimensionSeKey = \"fractal_dimension_se\"\n",
        "radiusWorstKey = \"radius_worst\"\n",
        "textureWorstKey = \"texture_worst\"\n",
        "perimeterWorstKey = \"perimeter_worst\"\n",
        "areaWorstKey = \"area_worst\"\n",
        "smoothnessWorstKey = \"smoothness_worst\"\n",
        "compactnessWorstKey = \"compactness_worst\"\n",
        "concavityWorstKey = \"concavity_worst\"\n",
        "concavePointsWorstKey = \"concave points_worst\"\n",
        "symmetryWorstKey = \"symmetry_worst\"\n",
        "fractalDimensionWorstKey = \"fractal_dimension_worst\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTrVCRD_cAO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_columns = [idKey, diagnosisKey, radiusMeanKey, textureMeanKey, perimeterMeanKey, areaMeanKey, smoothnessMeanKey, compactnessMeanKey, concavityMeanKey, concavePointsMeanKey, symmetryMeanKey, fractalDimensionMean, radiusSeKey, textureSeKey, perimeterSeKey, areaSeKey, smoothnessSeKey, compactnessSeKey, concavitySeKey, concavePointsSeKey, symmetrySeKey, fractalDimensionSeKey, radiusWorstKey, textureWorstKey, perimeterWorstKey, areaWorstKey, smoothnessWorstKey, compactnessWorstKey, concavityWorstKey, concavePointsWorstKey, symmetryWorstKey, fractalDimensionWorstKey]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUqoYUENcFrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_data():\n",
        "    df = pd.read_csv(train_filename, names= train_columns, delimiter=',', skiprows=1)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM2PPCb5cLy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = get_train_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHOSqzHkcPiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "0592bddb-fd0a-4b2b-cb74-36f1328f60f1"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>843786</td>\n",
              "      <td>M</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.1578</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  symmetry_worst  fractal_dimension_worst\n",
              "0    842517         M  ...          0.2750                  0.08902\n",
              "1  84300903         M  ...          0.3613                  0.08758\n",
              "2  84348301         M  ...          0.6638                  0.17300\n",
              "3  84358402         M  ...          0.2364                  0.07678\n",
              "4    843786         M  ...          0.3985                  0.12440\n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhrh1l10ciBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "dd260ff1-7e13-45d2-c784-3b2c914bb61f"
      },
      "source": [
        "train_data.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5.680000e+02</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.00000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "      <td>568.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.042382e+07</td>\n",
              "      <td>14.120491</td>\n",
              "      <td>19.305335</td>\n",
              "      <td>91.914754</td>\n",
              "      <td>654.279754</td>\n",
              "      <td>0.096321</td>\n",
              "      <td>0.104036</td>\n",
              "      <td>0.088427</td>\n",
              "      <td>0.048746</td>\n",
              "      <td>0.181055</td>\n",
              "      <td>0.062770</td>\n",
              "      <td>0.403958</td>\n",
              "      <td>1.217402</td>\n",
              "      <td>2.855984</td>\n",
              "      <td>40.138025</td>\n",
              "      <td>0.007042</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>0.031855</td>\n",
              "      <td>0.011789</td>\n",
              "      <td>0.020526</td>\n",
              "      <td>0.003791</td>\n",
              "      <td>16.25315</td>\n",
              "      <td>25.691919</td>\n",
              "      <td>107.125053</td>\n",
              "      <td>878.578873</td>\n",
              "      <td>0.132316</td>\n",
              "      <td>0.253541</td>\n",
              "      <td>0.271414</td>\n",
              "      <td>0.114341</td>\n",
              "      <td>0.289776</td>\n",
              "      <td>0.083884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.251246e+08</td>\n",
              "      <td>3.523416</td>\n",
              "      <td>4.288506</td>\n",
              "      <td>24.285848</td>\n",
              "      <td>351.923751</td>\n",
              "      <td>0.014046</td>\n",
              "      <td>0.052355</td>\n",
              "      <td>0.079294</td>\n",
              "      <td>0.038617</td>\n",
              "      <td>0.027319</td>\n",
              "      <td>0.007035</td>\n",
              "      <td>0.276038</td>\n",
              "      <td>0.551979</td>\n",
              "      <td>2.009288</td>\n",
              "      <td>45.282406</td>\n",
              "      <td>0.003005</td>\n",
              "      <td>0.017897</td>\n",
              "      <td>0.030199</td>\n",
              "      <td>0.006173</td>\n",
              "      <td>0.008264</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>4.82232</td>\n",
              "      <td>6.141662</td>\n",
              "      <td>33.474687</td>\n",
              "      <td>567.846267</td>\n",
              "      <td>0.022818</td>\n",
              "      <td>0.156523</td>\n",
              "      <td>0.207989</td>\n",
              "      <td>0.065484</td>\n",
              "      <td>0.061508</td>\n",
              "      <td>0.018017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>8.670000e+03</td>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>7.93000</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.692225e+05</td>\n",
              "      <td>11.697500</td>\n",
              "      <td>16.177500</td>\n",
              "      <td>75.135000</td>\n",
              "      <td>420.175000</td>\n",
              "      <td>0.086290</td>\n",
              "      <td>0.064815</td>\n",
              "      <td>0.029540</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057697</td>\n",
              "      <td>0.232375</td>\n",
              "      <td>0.833150</td>\n",
              "      <td>1.605000</td>\n",
              "      <td>17.850000</td>\n",
              "      <td>0.005166</td>\n",
              "      <td>0.013048</td>\n",
              "      <td>0.015063</td>\n",
              "      <td>0.007634</td>\n",
              "      <td>0.015128</td>\n",
              "      <td>0.002244</td>\n",
              "      <td>13.01000</td>\n",
              "      <td>21.095000</td>\n",
              "      <td>84.102500</td>\n",
              "      <td>514.975000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.146900</td>\n",
              "      <td>0.114475</td>\n",
              "      <td>0.064730</td>\n",
              "      <td>0.250350</td>\n",
              "      <td>0.071412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.061570e+05</td>\n",
              "      <td>13.355000</td>\n",
              "      <td>18.855000</td>\n",
              "      <td>86.210000</td>\n",
              "      <td>548.750000</td>\n",
              "      <td>0.095865</td>\n",
              "      <td>0.092525</td>\n",
              "      <td>0.061400</td>\n",
              "      <td>0.033455</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061515</td>\n",
              "      <td>0.323950</td>\n",
              "      <td>1.109500</td>\n",
              "      <td>2.285500</td>\n",
              "      <td>24.485000</td>\n",
              "      <td>0.006374</td>\n",
              "      <td>0.020435</td>\n",
              "      <td>0.025875</td>\n",
              "      <td>0.010920</td>\n",
              "      <td>0.018725</td>\n",
              "      <td>0.003162</td>\n",
              "      <td>14.96500</td>\n",
              "      <td>25.425000</td>\n",
              "      <td>97.655000</td>\n",
              "      <td>685.550000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211850</td>\n",
              "      <td>0.226550</td>\n",
              "      <td>0.099840</td>\n",
              "      <td>0.282050</td>\n",
              "      <td>0.080015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.825022e+06</td>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.802500</td>\n",
              "      <td>103.875000</td>\n",
              "      <td>782.625000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.129650</td>\n",
              "      <td>0.073730</td>\n",
              "      <td>0.195625</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>0.477325</td>\n",
              "      <td>1.474250</td>\n",
              "      <td>3.336750</td>\n",
              "      <td>45.017500</td>\n",
              "      <td>0.008151</td>\n",
              "      <td>0.032217</td>\n",
              "      <td>0.041765</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.023397</td>\n",
              "      <td>0.004526</td>\n",
              "      <td>18.76750</td>\n",
              "      <td>29.757500</td>\n",
              "      <td>125.175000</td>\n",
              "      <td>1073.500000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.337600</td>\n",
              "      <td>0.381400</td>\n",
              "      <td>0.161325</td>\n",
              "      <td>0.317675</td>\n",
              "      <td>0.092065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.113205e+08</td>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>2.873000</td>\n",
              "      <td>4.885000</td>\n",
              "      <td>21.980000</td>\n",
              "      <td>542.200000</td>\n",
              "      <td>0.031130</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.396000</td>\n",
              "      <td>0.052790</td>\n",
              "      <td>0.078950</td>\n",
              "      <td>0.029840</td>\n",
              "      <td>36.04000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "count  5.680000e+02   568.000000  ...      568.000000               568.000000\n",
              "mean   3.042382e+07    14.120491  ...        0.289776                 0.083884\n",
              "std    1.251246e+08     3.523416  ...        0.061508                 0.018017\n",
              "min    8.670000e+03     6.981000  ...        0.156500                 0.055040\n",
              "25%    8.692225e+05    11.697500  ...        0.250350                 0.071412\n",
              "50%    9.061570e+05    13.355000  ...        0.282050                 0.080015\n",
              "75%    8.825022e+06    15.780000  ...        0.317675                 0.092065\n",
              "max    9.113205e+08    28.110000  ...        0.663800                 0.207500\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGlmcNS1cpNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "e99e1b66-b167-40f4-ac99-e7c851008234"
      },
      "source": [
        "train_data.isnull().sum()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                         0\n",
              "diagnosis                  0\n",
              "radius_mean                0\n",
              "texture_mean               0\n",
              "perimeter_mean             0\n",
              "area_mean                  0\n",
              "smoothness_mean            0\n",
              "compactness_mean           0\n",
              "concavity_mean             0\n",
              "concave points_mean        0\n",
              "symmetry_mean              0\n",
              "fractal_dimension_mean     0\n",
              "radius_se                  0\n",
              "texture_se                 0\n",
              "perimeter_se               0\n",
              "area_se                    0\n",
              "smoothness_se              0\n",
              "compactness_se             0\n",
              "concavity_se               0\n",
              "concave points_se          0\n",
              "symmetry_se                0\n",
              "fractal_dimension_se       0\n",
              "radius_worst               0\n",
              "texture_worst              0\n",
              "perimeter_worst            0\n",
              "area_worst                 0\n",
              "smoothness_worst           0\n",
              "compactness_worst          0\n",
              "concavity_worst            0\n",
              "concave points_worst       0\n",
              "symmetry_worst             0\n",
              "fractal_dimension_worst    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N6YXrLccrLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c6c6ebee-83ac-4785-a654-979617f71360"
      },
      "source": [
        "print (\"Malignant\")\n",
        "print (train_data.area_mean[train_data.diagnosis == \"M\"].describe())\n",
        "print ()\n",
        "print (\"Benign\")\n",
        "print (train_data.area_mean[train_data.diagnosis == \"B\"].describe())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Malignant\n",
            "count     211.000000\n",
            "mean      978.269194\n",
            "std       368.809660\n",
            "min       361.600000\n",
            "25%       705.000000\n",
            "50%       930.900000\n",
            "75%      1204.500000\n",
            "max      2501.000000\n",
            "Name: area_mean, dtype: float64\n",
            "\n",
            "Benign\n",
            "count    357.000000\n",
            "mean     462.790196\n",
            "std      134.287118\n",
            "min      143.500000\n",
            "25%      378.200000\n",
            "50%      458.400000\n",
            "75%      551.100000\n",
            "max      992.100000\n",
            "Name: area_mean, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL7cjyZicxBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7ba1c7f7-e94f-4b82-825c-c6720b758409"
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
        "\n",
        "bins = 50\n",
        "\n",
        "ax1.hist(train_data.area_mean[train_data.diagnosis == \"M\"], bins = bins)\n",
        "ax1.set_title('Malignant')\n",
        "\n",
        "ax2.hist(train_data.area_mean[train_data.diagnosis == \"B\"], bins = bins)\n",
        "ax2.set_title('Benign')\n",
        "\n",
        "plt.xlabel('Area Mean')\n",
        "plt.ylabel('Number of Diagnosis')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAEWCAYAAACdXqrwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npFmSJElqYdIsSZIktfj/5rccR+xIoJkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9SueFDBc162",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "689cdde7-871d-4a6f-c398-ecdf482fdd4f"
      },
      "source": [
        "print (\"Malignant\")\n",
        "print (train_data.area_worst[train_data.diagnosis == \"M\"].describe())\n",
        "print ()\n",
        "print (\"Benign\")\n",
        "print (train_data.area_worst[train_data.diagnosis == \"B\"].describe())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Malignant\n",
            "count     211.000000\n",
            "mean     1419.458294\n",
            "std       597.966989\n",
            "min       508.100000\n",
            "25%       969.200000\n",
            "50%      1302.000000\n",
            "75%      1702.500000\n",
            "max      4254.000000\n",
            "Name: area_worst, dtype: float64\n",
            "\n",
            "Benign\n",
            "count     357.000000\n",
            "mean      558.899440\n",
            "std       163.601424\n",
            "min       185.200000\n",
            "25%       447.100000\n",
            "50%       547.400000\n",
            "75%       670.000000\n",
            "max      1210.000000\n",
            "Name: area_worst, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5iKaC7jc6pV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8328d79e-22f1-4a1c-bbfe-50f15ba9e9dd"
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4))\n",
        "\n",
        "bins = 30\n",
        "\n",
        "ax1.hist(train_data.area_worst[train_data.diagnosis == \"M\"], bins = bins)\n",
        "ax1.set_title('Malignant')\n",
        "\n",
        "ax2.hist(train_data.area_worst[train_data.diagnosis == \"B\"], bins = bins)\n",
        "ax2.set_title('Benign')\n",
        "\n",
        "plt.xlabel('Area Worst')\n",
        "plt.ylabel('Number of Diagnosis')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAEWCAYAAACkORurAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnisLj9xc_Me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Select only the rest of the features.\n",
        "r_data = train_data.drop([idKey, areaMeanKey, areaWorstKey, diagnosisKey], axis=1)\n",
        "r_features = r_data.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm6P4fFudItO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "10b93f79-e8c7-48a8-d117-c139c6f1aa2a"
      },
      "source": [
        "r_features"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'smoothness_mean',\n",
              "       'compactness_mean', 'concavity_mean', 'concave points_mean',\n",
              "       'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se',\n",
              "       'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se',\n",
              "       'concavity_se', 'concave points_se', 'symmetry_se',\n",
              "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
              "       'perimeter_worst', 'smoothness_worst', 'compactness_worst',\n",
              "       'concavity_worst', 'concave points_worst', 'symmetry_worst',\n",
              "       'fractal_dimension_worst'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONlAJTBFdLq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,28*4))\n",
        "gs = gridspec.GridSpec(28, 1)\n",
        "for i, cn in enumerate(r_data[r_features]):\n",
        "    ax = plt.subplot(gs[i])\n",
        "    sns.distplot(train_data[cn][train_data.diagnosis == \"M\"], bins=50)\n",
        "    sns.distplot(train_data[cn][train_data.diagnosis == \"B\"], bins=50)\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_title('histogram of feature: ' + str(cn))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdlLs8RjdT7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.loc[train_data.diagnosis == \"M\", 'diagnosis'] = 1\n",
        "train_data.loc[train_data.diagnosis == \"B\", 'diagnosis'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnjUbNuZdapE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "2ec56ad1-f16e-4946-e8c9-8ea2ff8bae60"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>malignant</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>benign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>843786</td>\n",
              "      <td>1</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.1578</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  malignant  ...  fractal_dimension_worst  benign\n",
              "0    842517          1  ...                  0.08902       0\n",
              "1  84300903          1  ...                  0.08758       0\n",
              "2  84348301          1  ...                  0.17300       0\n",
              "3  84358402          1  ...                  0.07678       0\n",
              "4    843786          1  ...                  0.12440       0\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbohdhpkdfe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a new feature for benign (non-malignant) diagnosis.\n",
        "train_data.loc[train_data.diagnosis == 0, 'benign'] = 1\n",
        "train_data.loc[train_data.diagnosis == 1, 'benign'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9zXoz2kd2f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['benign'] = train_data.benign.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOKVZWuNeAyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.rename(columns={'diagnosis': 'malignant'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4fak6x5ePZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "68903769-c280-4d69-d2a9-818c0a2e166c"
      },
      "source": [
        "print(train_data.benign.value_counts())\n",
        "print()\n",
        "print(train_data.malignant.value_counts())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    357\n",
            "0    211\n",
            "Name: benign, dtype: int64\n",
            "\n",
            "0    357\n",
            "1    211\n",
            "Name: malignant, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l65An4o1eRNe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "56346887-6f5c-42fc-e59a-a0e301c44829"
      },
      "source": [
        "pd.set_option(\"display.max_columns\",101)\n",
        "train_data.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>malignant</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>benign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842517</td>\n",
              "      <td>1</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>84300903</td>\n",
              "      <td>1</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84348301</td>\n",
              "      <td>1</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84358402</td>\n",
              "      <td>1</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>843786</td>\n",
              "      <td>1</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.1578</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.03345</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.01137</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  malignant  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842517          1        20.57         17.77          132.90     1326.0   \n",
              "1  84300903          1        19.69         21.25          130.00     1203.0   \n",
              "2  84348301          1        11.42         20.38           77.58      386.1   \n",
              "3  84358402          1        20.29         14.34          135.10     1297.0   \n",
              "4    843786          1        12.45         15.70           82.57      477.1   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.08474           0.07864          0.0869              0.07017   \n",
              "1          0.10960           0.15990          0.1974              0.12790   \n",
              "2          0.14250           0.28390          0.2414              0.10520   \n",
              "3          0.10030           0.13280          0.1980              0.10430   \n",
              "4          0.12780           0.17000          0.1578              0.08089   \n",
              "\n",
              "   symmetry_mean  fractal_dimension_mean  radius_se  texture_se  perimeter_se  \\\n",
              "0         0.1812                 0.05667     0.5435      0.7339         3.398   \n",
              "1         0.2069                 0.05999     0.7456      0.7869         4.585   \n",
              "2         0.2597                 0.09744     0.4956      1.1560         3.445   \n",
              "3         0.1809                 0.05883     0.7572      0.7813         5.438   \n",
              "4         0.2087                 0.07613     0.3345      0.8902         2.217   \n",
              "\n",
              "   area_se  smoothness_se  compactness_se  concavity_se  concave points_se  \\\n",
              "0    74.08       0.005225         0.01308       0.01860            0.01340   \n",
              "1    94.03       0.006150         0.04006       0.03832            0.02058   \n",
              "2    27.23       0.009110         0.07458       0.05661            0.01867   \n",
              "3    94.44       0.011490         0.02461       0.05688            0.01885   \n",
              "4    27.19       0.007510         0.03345       0.03672            0.01137   \n",
              "\n",
              "   symmetry_se  fractal_dimension_se  radius_worst  texture_worst  \\\n",
              "0      0.01389              0.003532         24.99          23.41   \n",
              "1      0.02250              0.004571         23.57          25.53   \n",
              "2      0.05963              0.009208         14.91          26.50   \n",
              "3      0.01756              0.005115         22.54          16.67   \n",
              "4      0.02165              0.005082         15.47          23.75   \n",
              "\n",
              "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "0           158.80      1956.0            0.1238             0.1866   \n",
              "1           152.50      1709.0            0.1444             0.4245   \n",
              "2            98.87       567.7            0.2098             0.8663   \n",
              "3           152.20      1575.0            0.1374             0.2050   \n",
              "4           103.40       741.6            0.1791             0.5249   \n",
              "\n",
              "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0           0.2416                0.1860          0.2750   \n",
              "1           0.4504                0.2430          0.3613   \n",
              "2           0.6869                0.2575          0.6638   \n",
              "3           0.4000                0.1625          0.2364   \n",
              "4           0.5355                0.1741          0.3985   \n",
              "\n",
              "   fractal_dimension_worst  benign  \n",
              "0                  0.08902       0  \n",
              "1                  0.08758       0  \n",
              "2                  0.17300       0  \n",
              "3                  0.07678       0  \n",
              "4                  0.12440       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQG58GTIec6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dataframes of only Malignant and Benign diagnosis.\n",
        "Malignant = train_data[train_data.malignant == 1]\n",
        "Benign = train_data[train_data.benign == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYba-TY2eqTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set train_X equal to 80% of the malignant diagnosis.\n",
        "train_X = Malignant.sample(frac=0.8)\n",
        "count_Malignants = len(train_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phLJiobXe1f0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add 80% of the benign diagnosis to train_X.\n",
        "train_X = pd.concat([train_X, Benign.sample(frac = 0.8)], axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpFFo5OVfAwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_X contains all the diagnostics not in train_X.\n",
        "test_X = train_data.loc[~train_data.index.isin(train_X.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOSkTSgxfMe9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle the dataframes so that the training is done in a random order.\n",
        "train_X = shuffle(train_X)\n",
        "test_X = shuffle(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cvvqu6BfWXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add our target features to train_Y and test_Y\n",
        "\n",
        "train_Y = train_X.malignant\n",
        "train_Y = pd.concat([train_Y, train_X.benign], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOAE9rW5fiAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_Y = test_X.malignant\n",
        "test_Y = pd.concat([test_Y, test_X.benign], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U42JnX7fnC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop target features from train_X and test_X\n",
        "\n",
        "train_X = train_X.drop(['malignant','benign'], axis = 1)\n",
        "test_X = test_X.drop(['malignant','benign'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZgF-OEWfu7H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "944875b1-283f-40cc-9d1b-040281062429"
      },
      "source": [
        "# Check to ensure all of the training/testing dataframes are of the correct length\n",
        "\n",
        "print(len(train_X))\n",
        "print(len(train_Y))\n",
        "print(len(test_X))\n",
        "print(len(test_Y))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "455\n",
            "455\n",
            "113\n",
            "113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X0G25o8f5qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = train_X.columns.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko1y80j-f7s2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "236ccc78-f109-4ca2-fc88-17c097eea819"
      },
      "source": [
        "features"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['id', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
              "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
              "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
              "       'radius_se', 'texture_se', 'perimeter_se', 'area_se',\n",
              "       'smoothness_se', 'compactness_se', 'concavity_se',\n",
              "       'concave points_se', 'symmetry_se', 'fractal_dimension_se',\n",
              "       'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst',\n",
              "       'smoothness_worst', 'compactness_worst', 'concavity_worst',\n",
              "       'concave points_worst', 'symmetry_worst',\n",
              "       'fractal_dimension_worst'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU8zy2KLgDQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transform each feature in features so that it has a mean of 0 and standard deviation of 1; This helps with training the softmax algorithm.\n",
        "\n",
        "for feature in features:\n",
        "    mean, std = train_data[feature].mean(), train_data[feature].std()\n",
        "    train_X.loc[:, feature] = (train_X[feature] - mean) / std\n",
        "    test_X.loc[:, feature] = (test_X[feature] - mean) / std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_rhIsbcgIyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "\n",
        "learning_rate = 0.005\n",
        "training_dropout = 0.9\n",
        "display_step = 1\n",
        "training_epochs = 5\n",
        "batch_size = 100\n",
        "accuracy_history = [] \n",
        "cost_history = []\n",
        "valid_accuracy_history = [] \n",
        "valid_cost_history = [] \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnLnVfOSgP8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of input nodes\n",
        "\n",
        "input_nodes = train_X.shape[1]\n",
        "# Number of labels (malignant and benign)\n",
        "\n",
        "num_labels = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqg1nRINgZW5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f32fbaff-b309-40d6-d6d9-b090b5d58040"
      },
      "source": [
        "# Split the testing data into validation and testing sets\n",
        "\n",
        "split = int(len(test_Y)/2)\n",
        "\n",
        "train_size = train_X.shape[0]\n",
        "n_samples = train_Y.shape[0]\n",
        "\n",
        "input_X = train_X.as_matrix()\n",
        "input_Y = train_Y.as_matrix()\n",
        "input_X_valid = test_X.as_matrix()[:split]\n",
        "input_Y_valid = test_Y.as_matrix()[:split]\n",
        "input_X_test = test_X.as_matrix()[split:]\n",
        "input_Y_test = test_Y.as_matrix()[split:]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCBX1zaNgjEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_hidden_nodes(nodes):\n",
        "    return (((2 * nodes)/3) + num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkYPojQpgnhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "889413bd-d0af-4fe8-a030-3e350e950c95"
      },
      "source": [
        "#Number of nodes in each hidden layer\n",
        "\n",
        "hidden_nodes1 = round(calculate_hidden_nodes(input_nodes))\n",
        "hidden_nodes2 = round(calculate_hidden_nodes(hidden_nodes1))\n",
        "hidden_nodes3 = round(calculate_hidden_nodes(hidden_nodes2))\n",
        "print(input_nodes, hidden_nodes1, hidden_nodes2, hidden_nodes3)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31 23 17 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JANnCzV0gu5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Percent of nodes to keep during dropout.\n",
        "\n",
        "pkeep = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQW8Ul_5g03f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, input_nodes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEZ8Ce92g5_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Layer 1\n",
        "\n",
        "W1 = tf.Variable(tf.truncated_normal([input_nodes, hidden_nodes1], stddev = 0.1))\n",
        "b1 = tf.Variable(tf.zeros([hidden_nodes1]))\n",
        "y1 = tf.nn.relu(tf.matmul(x, W1) + b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUVyUU8LhCAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7945e431-8dca-4359-e15e-4f52b4de1f41"
      },
      "source": [
        "# Layer 2\n",
        "\n",
        "W2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2], stddev = 0.1))\n",
        "b2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
        "y2 = tf.nn.relu(tf.matmul(y1, W2) + b2)\n",
        "# Layer 3\n",
        "\n",
        "W3 = tf.Variable(tf.truncated_normal([hidden_nodes2, hidden_nodes3], stddev = 0.1)) \n",
        "b3 = tf.Variable(tf.zeros([hidden_nodes3]))\n",
        "y3 = tf.nn.relu(tf.matmul(y2, W3) + b3)\n",
        "y3 = tf.nn.dropout(y3, pkeep)\n",
        "# Layer 4\n",
        "\n",
        "W4 = tf.Variable(tf.truncated_normal([hidden_nodes3, 2], stddev = 0.1)) \n",
        "b4 = tf.Variable(tf.zeros([2]))\n",
        "y4 = tf.nn.softmax(tf.matmul(y3, W4) + b4)\n",
        "#Output\n",
        "\n",
        "y = y4\n",
        "y_ = tf.placeholder(tf.float32, [None, num_labels]) \n",
        "# Minimize error using cross entropy\n",
        "\n",
        "cost = -tf.reduce_sum(y_ * tf.log(y))\n",
        "# AdamOptimizer\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "# Test Model\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "# Calculate accuracy\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "# Initializing the variables\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-50-ec9f3e5d8cba>:10: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01l-4zO4hiNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "1c5bfe2b-e2dc-4fb1-cffd-9893372a5e01"
      },
      "source": [
        "# Launch the graph\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for epoch in range(training_epochs): \n",
        "        for batch in range(int(n_samples/batch_size)):\n",
        "            batch_x = input_X[batch * batch_size : (1 + batch) * batch_size]\n",
        "            batch_y = input_Y[batch * batch_size : (1 + batch) * batch_size]\n",
        "\n",
        "            sess.run([optimizer], feed_dict={x: batch_x, \n",
        "                                             y_: batch_y,\n",
        "                                             pkeep: training_dropout})\n",
        "\n",
        "        # Display logs after every 10 epochs\n",
        "        if (epoch) % display_step == 0:\n",
        "            train_accuracy, newCost = sess.run([accuracy, cost], \n",
        "                                               feed_dict={x: input_X, y_: input_Y, \n",
        "                                                          pkeep: training_dropout})\n",
        "\n",
        "            valid_accuracy, valid_newCost = sess.run([accuracy, cost], \n",
        "                                                     feed_dict={x: input_X_valid, \n",
        "                                                                y_: input_Y_valid, pkeep: 1})\n",
        "\n",
        "            print (\"Epoch:\", epoch, \"Acc =\", \"{:.5f}\".format(train_accuracy), \n",
        "                   \"Cost =\", \"{:.5f}\".format(newCost), \n",
        "                   \"Valid_Acc =\", \"{:.5f}\".format(valid_accuracy), \n",
        "                   \"Valid_Cost = \", \"{:.5f}\".format(valid_newCost))\n",
        "            \n",
        "            # Record the results of the model\n",
        "            accuracy_history.append(train_accuracy)\n",
        "            cost_history.append(newCost)\n",
        "            valid_accuracy_history.append(valid_accuracy)\n",
        "            valid_cost_history.append(valid_newCost)\n",
        "            \n",
        "            # If the model does not improve after 15 logs, stop the training.\n",
        "            if valid_accuracy < max(valid_accuracy_history) and epoch > 100:\n",
        "                stop_early += 1\n",
        "                if stop_early == 15:\n",
        "                    break\n",
        "            else:\n",
        "                stop_early = 0\n",
        "            \n",
        "    print(\"Optimization Finished!\")\n",
        "    \n",
        "    # Plot the accuracy and cost summaries \n",
        "    f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,4))\n",
        "\n",
        "    ax1.plot(accuracy_history, color='b') # blue\n",
        "    ax1.plot(valid_accuracy_history, color='g') # green\n",
        "    ax1.set_title('Accuracy')\n",
        "\n",
        "    ax2.plot(cost_history, color='b')\n",
        "    ax2.plot(valid_cost_history, color='g')\n",
        "    ax2.set_title('Cost')\n",
        "\n",
        "    plt.xlabel('Epochs (x10)')\n",
        "    plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Acc = 0.62857 Cost = 305.24786 Valid_Acc = 0.58929 Valid_Cost =  37.83236\n",
            "Epoch: 1 Acc = 0.67473 Cost = 277.36234 Valid_Acc = 0.62500 Valid_Cost =  35.04304\n",
            "Epoch: 2 Acc = 0.85714 Cost = 219.54773 Valid_Acc = 0.87500 Valid_Cost =  29.08087\n",
            "Epoch: 3 Acc = 0.93187 Cost = 146.65115 Valid_Acc = 0.89286 Valid_Cost =  22.01895\n",
            "Epoch: 4 Acc = 0.94725 Cost = 98.11472 Valid_Acc = 0.91071 Valid_Cost =  18.01717\n",
            "Optimization Finished!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAEWCAYAAACkFdnuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAM2Vj5h76c",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "After using the AdamOptimizer model with all of the features in our Neural Network, it gives a prediction accuracy of ~96% and a cross-validation score of ~96% for the test data set. This models performs reasonably well and I suppose that if we have created new features, we could have built a more useful neural network."
      ]
    }
  ]
}